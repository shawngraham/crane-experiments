{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawngraham/crane-experiments/blob/master/generative/dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UjrmTw7wOLoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e8896ff-c64f-4a24-c6b0-9b9927a635a6"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pqw7wwFyhcEZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "+ using https://github.com/genekogan/DCGAN-tensorflow \n",
        "+ git clone wouldn't work though; pieces loaded separately through the file manager\n",
        "+ remember to preprocess files a la https://electricarchaeology.ca/2018/07/29/sticking-it-to-dcgan/\n",
        "+ don't know if these files will still be here or not when I get back. \n",
        "+ there's a way of mounting google drive to all this\n",
        "+ because this creates checkpoints, can run the main.py over and over again for better and better results\n",
        "+ should graph the d_loss, g_loss to see if this thing is getting any better\n",
        "+ don't have enough training photos"
      ]
    },
    {
      "metadata": {
        "id": "BIBq3eGmTr2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rm -r data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NNDOP-QcOQIy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip airphotos.zip -d data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWG0md4aQwID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6775
        },
        "outputId": "93663188-3219-4e00-d7ef-3c6c58c88205"
      },
      "cell_type": "code",
      "source": [
        "!python main.py --dataset all-images --input_height=128 --output_height=128 --train --crop"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'batch_size': <absl.flags._flag.Flag object at 0x7fe7267727b8>,\n",
            " 'beta1': <absl.flags._flag.Flag object at 0x7fe726772128>,\n",
            " 'checkpoint_dir': <absl.flags._flag.Flag object at 0x7fe71a3ffcf8>,\n",
            " 'crop': <absl.flags._flag.BooleanFlag object at 0x7fe71a3ffeb8>,\n",
            " 'data_dir': <absl.flags._flag.Flag object at 0x7fe71a3ffd68>,\n",
            " 'dataset': <absl.flags._flag.Flag object at 0x7fe71a3ffbe0>,\n",
            " 'epoch': <absl.flags._flag.Flag object at 0x7fe783bee208>,\n",
            " 'generate_test_images': <absl.flags._flag.Flag object at 0x7fe71a3fffd0>,\n",
            " 'h': <tensorflow.python.platform.app._HelpFlag object at 0x7fe71a406048>,\n",
            " 'help': <tensorflow.python.platform.app._HelpFlag object at 0x7fe71a406048>,\n",
            " 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x7fe71a4060f0>,\n",
            " 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x7fe71a406160>,\n",
            " 'input_fname_pattern': <absl.flags._flag.Flag object at 0x7fe71a3ffc50>,\n",
            " 'input_height': <absl.flags._flag.Flag object at 0x7fe726772b38>,\n",
            " 'input_width': <absl.flags._flag.Flag object at 0x7fe71a3ffa58>,\n",
            " 'learning_rate': <absl.flags._flag.Flag object at 0x7fe7275ca4a8>,\n",
            " 'output_height': <absl.flags._flag.Flag object at 0x7fe71a3ffac8>,\n",
            " 'output_width': <absl.flags._flag.Flag object at 0x7fe71a3ffb70>,\n",
            " 'sample_dir': <absl.flags._flag.Flag object at 0x7fe71a3ffdd8>,\n",
            " 'train': <absl.flags._flag.BooleanFlag object at 0x7fe71a3ffe10>,\n",
            " 'train_size': <absl.flags._flag.Flag object at 0x7fe726772710>,\n",
            " 'visualize': <absl.flags._flag.BooleanFlag object at 0x7fe71a3fff28>}\n",
            "2019-03-20 00:38:07.220047: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-03-20 00:38:07.220322: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x272a680 executing computations on platform Host. Devices:\n",
            "2019-03-20 00:38:07.220374: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-03-20 00:38:07.295511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-03-20 00:38:07.296100: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2729fa0 executing computations on platform CUDA. Devices:\n",
            "2019-03-20 00:38:07.296143: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-03-20 00:38:07.296541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.30GiB\n",
            "2019-03-20 00:38:07.296576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-03-20 00:38:07.676620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-03-20 00:38:07.676706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-03-20 00:38:07.676737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-03-20 00:38:07.677055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9970 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "---------\n",
            "Variables: name (type shape) [size]\n",
            "---------\n",
            "generator/g_h0_lin/Matrix:0 (float32_ref 100x32768) [3276800, bytes: 13107200]\n",
            "generator/g_h0_lin/bias:0 (float32_ref 32768) [32768, bytes: 131072]\n",
            "generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
            "generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
            "generator/g_h1/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
            "generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/g_h2/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
            "generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/g_h3/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
            "generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/g_h4/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
            "generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]\n",
            "discriminator/d_h0_conv/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
            "discriminator/d_h0_conv/biases:0 (float32_ref 64) [64, bytes: 256]\n",
            "discriminator/d_h1_conv/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
            "discriminator/d_h1_conv/biases:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/d_bn1/beta:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/d_bn1/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/d_h2_conv/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
            "discriminator/d_h2_conv/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/d_bn2/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/d_bn2/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/d_h3_conv/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
            "discriminator/d_h3_conv/biases:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/d_bn3/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/d_bn3/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/d_h4_lin/Matrix:0 (float32_ref 32768x1) [32768, bytes: 131072]\n",
            "discriminator/d_h4_lin/bias:0 (float32_ref 1) [1, bytes: 4]\n",
            "Total size of variables: 11958660\n",
            "Total bytes of variables: 47834640\n",
            " [*] Reading checkpoints...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            " [*] Success to read DCGAN.model-2\n",
            " [*] Load SUCCESS\n",
            "2019-03-20 00:38:15.004190: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Epoch: [ 0/25] [   0/   8] time: 10.1845, d_loss: 13.57575417, g_loss: 0.00000683\n",
            "Epoch: [ 0/25] [   1/   8] time: 11.8147, d_loss: 13.46449089, g_loss: 0.00001460\n",
            "Epoch: [ 0/25] [   2/   8] time: 13.4093, d_loss: 14.46928024, g_loss: 0.00000370\n",
            "Epoch: [ 0/25] [   3/   8] time: 14.9631, d_loss: 13.06265736, g_loss: 0.00002030\n",
            "Epoch: [ 0/25] [   4/   8] time: 16.5208, d_loss: 11.50978184, g_loss: 0.00004678\n",
            "Epoch: [ 0/25] [   5/   8] time: 18.0905, d_loss: 11.27710056, g_loss: 0.00003373\n",
            "Epoch: [ 0/25] [   6/   8] time: 19.6678, d_loss: 15.86191368, g_loss: 0.00000086\n",
            "Epoch: [ 0/25] [   7/   8] time: 21.2420, d_loss: 14.92530823, g_loss: 0.00000228\n",
            "Epoch: [ 1/25] [   0/   8] time: 22.8275, d_loss: 20.74534225, g_loss: 0.00000002\n",
            "Epoch: [ 1/25] [   1/   8] time: 24.3807, d_loss: 20.27909279, g_loss: 0.00000005\n",
            "Epoch: [ 1/25] [   2/   8] time: 25.9391, d_loss: 17.27254486, g_loss: 0.00000790\n",
            "Epoch: [ 1/25] [   3/   8] time: 27.4948, d_loss: 17.67336273, g_loss: 0.00000128\n",
            "Epoch: [ 1/25] [   4/   8] time: 29.0723, d_loss: 6.78695488, g_loss: 0.09294195\n",
            "Epoch: [ 1/25] [   5/   8] time: 30.6303, d_loss: 13.43733883, g_loss: 0.00000703\n",
            "Epoch: [ 1/25] [   6/   8] time: 32.2020, d_loss: 1.83834291, g_loss: 1.10374117\n",
            "Epoch: [ 1/25] [   7/   8] time: 33.7630, d_loss: 13.68166542, g_loss: 0.00000225\n",
            "Epoch: [ 2/25] [   0/   8] time: 35.3212, d_loss: 0.81505072, g_loss: 4.09585381\n",
            "Epoch: [ 2/25] [   1/   8] time: 36.8818, d_loss: 17.59294510, g_loss: 0.00000064\n",
            "Epoch: [ 2/25] [   2/   8] time: 38.4388, d_loss: 0.71120036, g_loss: 5.36488628\n",
            "Epoch: [ 2/25] [   3/   8] time: 40.0478, d_loss: 11.52475929, g_loss: 0.00028226\n",
            "Epoch: [ 2/25] [   4/   8] time: 41.6171, d_loss: 1.59904110, g_loss: 13.61991310\n",
            "Epoch: [ 2/25] [   5/   8] time: 43.1896, d_loss: 4.17095375, g_loss: 0.21156897\n",
            "Epoch: [ 2/25] [   6/   8] time: 44.7657, d_loss: 9.94872379, g_loss: 0.00014995\n",
            "Epoch: [ 2/25] [   7/   8] time: 46.3173, d_loss: 0.76956958, g_loss: 25.98131180\n",
            "Epoch: [ 3/25] [   0/   8] time: 47.8602, d_loss: 0.27633604, g_loss: 18.07533455\n",
            "Epoch: [ 3/25] [   1/   8] time: 49.3911, d_loss: 3.28802276, g_loss: 0.22997564\n",
            "Epoch: [ 3/25] [   2/   8] time: 50.9559, d_loss: 9.76722431, g_loss: 0.00014411\n",
            "Epoch: [ 3/25] [   3/   8] time: 52.5071, d_loss: 1.09720492, g_loss: 30.18211365\n",
            "Epoch: [ 3/25] [   4/   8] time: 54.0603, d_loss: 0.38418132, g_loss: 27.60739326\n",
            "Epoch: [ 3/25] [   5/   8] time: 55.6059, d_loss: 0.20158879, g_loss: 6.16595173\n",
            "Epoch: [ 3/25] [   6/   8] time: 57.1690, d_loss: 11.45843983, g_loss: 0.00002683\n",
            "Epoch: [ 3/25] [   7/   8] time: 58.7380, d_loss: 1.60289145, g_loss: 26.77665329\n",
            "Epoch: [ 4/25] [   0/   8] time: 60.3025, d_loss: 0.14826787, g_loss: 24.37134361\n",
            "Epoch: [ 4/25] [   1/   8] time: 61.8790, d_loss: 0.61095327, g_loss: 9.85444450\n",
            "Epoch: [ 4/25] [   2/   8] time: 63.4587, d_loss: 6.95491505, g_loss: 0.00282866\n",
            "Epoch: [ 4/25] [   3/   8] time: 65.0327, d_loss: 1.87894273, g_loss: 32.78156281\n",
            "Epoch: [ 4/25] [   4/   8] time: 66.6111, d_loss: 0.33820322, g_loss: 35.98306274\n",
            "Epoch: [ 4/25] [   5/   8] time: 68.1950, d_loss: 0.33125722, g_loss: 26.91847420\n",
            "Epoch: [ 4/25] [   6/   8] time: 69.7656, d_loss: 0.00317144, g_loss: 14.45305252\n",
            "Epoch: [ 4/25] [   7/   8] time: 71.3387, d_loss: 5.67260504, g_loss: 0.02470552\n",
            "Epoch: [ 5/25] [   0/   8] time: 72.9158, d_loss: 1.71148157, g_loss: 15.55086422\n",
            "Epoch: [ 5/25] [   1/   8] time: 74.5000, d_loss: 1.77451277, g_loss: 1.52562165\n",
            "Epoch: [ 5/25] [   2/   8] time: 76.0744, d_loss: 8.99243164, g_loss: 0.03416795\n",
            "Epoch: [ 5/25] [   3/   8] time: 77.6420, d_loss: 5.33612251, g_loss: 21.62792587\n",
            "Epoch: [ 5/25] [   4/   8] time: 79.2132, d_loss: 1.97672105, g_loss: 7.05262756\n",
            "Epoch: [ 5/25] [   5/   8] time: 80.7808, d_loss: 11.43015575, g_loss: 0.00685849\n",
            "Epoch: [ 5/25] [   6/   8] time: 82.3454, d_loss: 1.93134737, g_loss: 26.80955696\n",
            "Epoch: [ 5/25] [   7/   8] time: 83.9038, d_loss: 2.38300276, g_loss: 13.98366356\n",
            "Epoch: [ 6/25] [   0/   8] time: 85.4933, d_loss: 5.17684889, g_loss: 0.95401573\n",
            "Epoch: [ 6/25] [   1/   8] time: 87.0807, d_loss: 2.73491168, g_loss: 3.66321945\n",
            "Epoch: [ 6/25] [   2/   8] time: 88.6605, d_loss: 6.83828878, g_loss: 0.00962219\n",
            "Epoch: [ 6/25] [   3/   8] time: 90.2397, d_loss: 5.63633156, g_loss: 4.38716984\n",
            "Epoch: [ 6/25] [   4/   8] time: 91.8007, d_loss: 5.03493786, g_loss: 0.20028464\n",
            "Epoch: [ 6/25] [   5/   8] time: 93.3713, d_loss: 2.71628618, g_loss: 1.74452841\n",
            "Epoch: [ 6/25] [   6/   8] time: 94.9338, d_loss: 4.71497536, g_loss: 0.32514712\n",
            "Epoch: [ 6/25] [   7/   8] time: 96.5065, d_loss: 4.45114088, g_loss: 4.75547981\n",
            "Epoch: [ 7/25] [   0/   8] time: 98.0711, d_loss: 2.98951793, g_loss: 0.80291677\n",
            "Epoch: [ 7/25] [   1/   8] time: 99.6486, d_loss: 1.60211825, g_loss: 1.45741630\n",
            "Epoch: [ 7/25] [   2/   8] time: 101.2155, d_loss: 3.31397986, g_loss: 0.65831947\n",
            "Epoch: [ 7/25] [   3/   8] time: 102.7804, d_loss: 3.38052726, g_loss: 3.20593739\n",
            "Epoch: [ 7/25] [   4/   8] time: 104.3396, d_loss: 6.96028519, g_loss: 0.01847341\n",
            "Epoch: [ 7/25] [   5/   8] time: 105.9057, d_loss: 5.20324278, g_loss: 7.06903458\n",
            "Epoch: [ 7/25] [   6/   8] time: 107.4708, d_loss: 3.89869881, g_loss: 1.02670670\n",
            "Epoch: [ 7/25] [   7/   8] time: 109.0526, d_loss: 3.57779694, g_loss: 0.25897369\n",
            "Epoch: [ 8/25] [   0/   8] time: 110.6445, d_loss: 3.19487667, g_loss: 6.96747637\n",
            "Epoch: [ 8/25] [   1/   8] time: 112.2037, d_loss: 1.39956999, g_loss: 2.07520318\n",
            "Epoch: [ 8/25] [   2/   8] time: 113.7692, d_loss: 3.14090323, g_loss: 0.08033510\n",
            "Epoch: [ 8/25] [   3/   8] time: 115.3287, d_loss: 2.27189445, g_loss: 5.62905169\n",
            "Epoch: [ 8/25] [   4/   8] time: 116.8962, d_loss: 2.04704595, g_loss: 1.59529638\n",
            "Epoch: [ 8/25] [   5/   8] time: 118.4550, d_loss: 3.10705686, g_loss: 0.19394773\n",
            "Epoch: [ 8/25] [   6/   8] time: 120.0174, d_loss: 2.19518423, g_loss: 2.16741371\n",
            "Epoch: [ 8/25] [   7/   8] time: 121.6037, d_loss: 2.51544094, g_loss: 0.52937698\n",
            "Epoch: [ 9/25] [   0/   8] time: 123.1908, d_loss: 3.22269773, g_loss: 0.28297800\n",
            "Epoch: [ 9/25] [   1/   8] time: 124.7650, d_loss: 2.51649570, g_loss: 1.53947473\n",
            "Epoch: [ 9/25] [   2/   8] time: 126.3317, d_loss: 3.17807508, g_loss: 0.13727985\n",
            "Epoch: [ 9/25] [   3/   8] time: 127.8972, d_loss: 3.08201551, g_loss: 3.66455507\n",
            "Epoch: [ 9/25] [   4/   8] time: 129.4686, d_loss: 2.87863684, g_loss: 0.50551319\n",
            "Epoch: [ 9/25] [   5/   8] time: 131.0501, d_loss: 2.26852894, g_loss: 0.53780061\n",
            "Epoch: [ 9/25] [   6/   8] time: 132.6337, d_loss: 2.20357656, g_loss: 2.00460196\n",
            "Epoch: [ 9/25] [   7/   8] time: 134.2104, d_loss: 2.18779945, g_loss: 0.29039475\n",
            "Epoch: [10/25] [   0/   8] time: 135.8046, d_loss: 1.89081240, g_loss: 1.22855449\n",
            "Epoch: [10/25] [   1/   8] time: 137.3717, d_loss: 1.67134380, g_loss: 0.65054381\n",
            "Epoch: [10/25] [   2/   8] time: 138.9486, d_loss: 1.95829105, g_loss: 0.57562792\n",
            "Epoch: [10/25] [   3/   8] time: 140.5135, d_loss: 2.48619318, g_loss: 0.48951483\n",
            "Epoch: [10/25] [   4/   8] time: 142.1008, d_loss: 1.80645680, g_loss: 1.85942149\n",
            "Epoch: [10/25] [   5/   8] time: 143.6702, d_loss: 2.44655299, g_loss: 0.16712081\n",
            "Epoch: [10/25] [   6/   8] time: 145.2470, d_loss: 3.47855544, g_loss: 3.52029586\n",
            "Epoch: [10/25] [   7/   8] time: 146.8243, d_loss: 2.24246979, g_loss: 0.67998028\n",
            "Epoch: [11/25] [   0/   8] time: 148.3959, d_loss: 1.96605802, g_loss: 0.46837899\n",
            "Epoch: [11/25] [   1/   8] time: 149.9641, d_loss: 1.87337494, g_loss: 2.69292784\n",
            "Epoch: [11/25] [   2/   8] time: 151.5311, d_loss: 2.28211737, g_loss: 0.37903970\n",
            "Epoch: [11/25] [   3/   8] time: 153.1066, d_loss: 2.14233279, g_loss: 0.29734588\n",
            "Epoch: [11/25] [   4/   8] time: 154.6889, d_loss: 3.29747796, g_loss: 2.29552341\n",
            "Epoch: [11/25] [   5/   8] time: 156.2562, d_loss: 2.44812751, g_loss: 0.50562608\n",
            "Epoch: [11/25] [   6/   8] time: 157.8353, d_loss: 2.61847305, g_loss: 0.45630479\n",
            "Epoch: [11/25] [   7/   8] time: 159.3945, d_loss: 2.45149040, g_loss: 0.52058667\n",
            "Epoch: [12/25] [   0/   8] time: 160.9710, d_loss: 1.81276131, g_loss: 0.68632370\n",
            "Epoch: [12/25] [   1/   8] time: 162.5253, d_loss: 1.93036103, g_loss: 0.41629505\n",
            "Epoch: [12/25] [   2/   8] time: 164.1080, d_loss: 1.17649388, g_loss: 2.07065201\n",
            "[Sample] d_loss: 1.29573512, g_loss: 2.61771107\n",
            "Epoch: [12/25] [   3/   8] time: 166.3888, d_loss: 1.91385293, g_loss: 0.29307407\n",
            "Epoch: [12/25] [   4/   8] time: 167.9700, d_loss: 1.51978946, g_loss: 1.59593892\n",
            "Epoch: [12/25] [   5/   8] time: 169.5532, d_loss: 1.04713809, g_loss: 0.84948456\n",
            "Epoch: [12/25] [   6/   8] time: 171.1391, d_loss: 1.96477556, g_loss: 0.30605954\n",
            "Epoch: [12/25] [   7/   8] time: 172.7106, d_loss: 1.51197624, g_loss: 0.98297870\n",
            "Epoch: [13/25] [   0/   8] time: 174.2959, d_loss: 2.43073845, g_loss: 0.49900770\n",
            "Epoch: [13/25] [   1/   8] time: 175.8627, d_loss: 2.04785919, g_loss: 0.43892375\n",
            "Epoch: [13/25] [   2/   8] time: 177.4464, d_loss: 2.35325956, g_loss: 2.04353666\n",
            "Epoch: [13/25] [   3/   8] time: 179.0242, d_loss: 2.44768572, g_loss: 0.36293048\n",
            "Epoch: [13/25] [   4/   8] time: 180.6027, d_loss: 2.16086054, g_loss: 0.90981078\n",
            "Epoch: [13/25] [   5/   8] time: 182.1814, d_loss: 1.85073078, g_loss: 1.04945052\n",
            "Epoch: [13/25] [   6/   8] time: 183.7607, d_loss: 2.27813172, g_loss: 0.44437972\n",
            "Epoch: [13/25] [   7/   8] time: 185.3270, d_loss: 1.47291529, g_loss: 1.26081979\n",
            "Epoch: [14/25] [   0/   8] time: 186.8944, d_loss: 1.34641540, g_loss: 0.71447718\n",
            "Epoch: [14/25] [   1/   8] time: 188.4670, d_loss: 1.55688214, g_loss: 0.92786622\n",
            "Epoch: [14/25] [   2/   8] time: 190.0520, d_loss: 1.14366388, g_loss: 0.88332349\n",
            "Epoch: [14/25] [   3/   8] time: 191.6351, d_loss: 1.65990472, g_loss: 0.42678463\n",
            "Epoch: [14/25] [   4/   8] time: 193.2108, d_loss: 1.53125405, g_loss: 1.32050180\n",
            "Epoch: [14/25] [   5/   8] time: 194.7757, d_loss: 1.91677856, g_loss: 0.33330160\n",
            "Epoch: [14/25] [   6/   8] time: 196.3151, d_loss: 1.75721169, g_loss: 1.04554904\n",
            "Epoch: [14/25] [   7/   8] time: 197.8563, d_loss: 1.56315041, g_loss: 0.59041661\n",
            "Epoch: [15/25] [   0/   8] time: 199.4011, d_loss: 1.60955226, g_loss: 1.18103778\n",
            "Epoch: [15/25] [   1/   8] time: 200.9639, d_loss: 1.83132148, g_loss: 0.37292725\n",
            "Epoch: [15/25] [   2/   8] time: 202.5473, d_loss: 1.85315800, g_loss: 1.37627268\n",
            "Epoch: [15/25] [   3/   8] time: 204.1248, d_loss: 1.52545786, g_loss: 0.49201256\n",
            "Epoch: [15/25] [   4/   8] time: 205.6909, d_loss: 1.81084037, g_loss: 1.11458111\n",
            "Epoch: [15/25] [   5/   8] time: 207.2620, d_loss: 2.45320606, g_loss: 0.33653456\n",
            "Epoch: [15/25] [   6/   8] time: 208.8412, d_loss: 1.99347115, g_loss: 1.58730435\n",
            "Epoch: [15/25] [   7/   8] time: 210.4203, d_loss: 1.90166521, g_loss: 0.34583232\n",
            "Epoch: [16/25] [   0/   8] time: 211.9986, d_loss: 1.90213740, g_loss: 1.79463482\n",
            "Epoch: [16/25] [   1/   8] time: 213.5751, d_loss: 1.39665186, g_loss: 0.69409567\n",
            "Epoch: [16/25] [   2/   8] time: 215.1575, d_loss: 1.55147696, g_loss: 0.51894468\n",
            "Epoch: [16/25] [   3/   8] time: 216.7368, d_loss: 1.67819953, g_loss: 1.25648689\n",
            "Epoch: [16/25] [   4/   8] time: 218.3107, d_loss: 1.66750944, g_loss: 0.55423164\n",
            "Epoch: [16/25] [   5/   8] time: 219.8856, d_loss: 1.54784703, g_loss: 0.52568042\n",
            "Epoch: [16/25] [   6/   8] time: 221.4521, d_loss: 1.58464837, g_loss: 1.01252365\n",
            "Epoch: [16/25] [   7/   8] time: 223.1248, d_loss: 1.55786681, g_loss: 0.73493469\n",
            "Epoch: [17/25] [   0/   8] time: 224.7018, d_loss: 1.22377443, g_loss: 0.90787923\n",
            "Epoch: [17/25] [   1/   8] time: 226.2859, d_loss: 1.54016972, g_loss: 0.77642071\n",
            "Epoch: [17/25] [   2/   8] time: 227.8498, d_loss: 1.40344882, g_loss: 0.70599622\n",
            "Epoch: [17/25] [   3/   8] time: 229.4205, d_loss: 1.64997804, g_loss: 0.72636479\n",
            "Epoch: [17/25] [   4/   8] time: 230.9956, d_loss: 1.14199018, g_loss: 1.26565349\n",
            "Epoch: [17/25] [   5/   8] time: 232.5883, d_loss: 1.61163783, g_loss: 0.39770579\n",
            "Epoch: [17/25] [   6/   8] time: 234.1760, d_loss: 1.70302403, g_loss: 2.14974999\n",
            "Epoch: [17/25] [   7/   8] time: 235.7526, d_loss: 1.81966722, g_loss: 0.37481329\n",
            "Epoch: [18/25] [   0/   8] time: 237.3398, d_loss: 1.44644427, g_loss: 1.40315723\n",
            "Epoch: [18/25] [   1/   8] time: 238.9263, d_loss: 1.09525847, g_loss: 0.88011163\n",
            "Epoch: [18/25] [   2/   8] time: 240.4975, d_loss: 1.56288540, g_loss: 0.49501988\n",
            "Epoch: [18/25] [   3/   8] time: 242.0607, d_loss: 1.58648276, g_loss: 1.33489788\n",
            "Epoch: [18/25] [   4/   8] time: 243.6188, d_loss: 1.95731330, g_loss: 0.31368715\n",
            "Epoch: [18/25] [   5/   8] time: 245.1964, d_loss: 2.03974342, g_loss: 0.83170122\n",
            "Epoch: [18/25] [   6/   8] time: 246.7672, d_loss: 1.93273067, g_loss: 0.65207088\n",
            "Epoch: [18/25] [   7/   8] time: 248.3432, d_loss: 1.87343073, g_loss: 0.49268198\n",
            "Epoch: [19/25] [   0/   8] time: 249.9097, d_loss: 1.73391151, g_loss: 0.85918510\n",
            "Epoch: [19/25] [   1/   8] time: 251.4726, d_loss: 1.67987895, g_loss: 1.17644703\n",
            "Epoch: [19/25] [   2/   8] time: 253.0398, d_loss: 1.72980952, g_loss: 0.48729360\n",
            "Epoch: [19/25] [   3/   8] time: 254.6126, d_loss: 1.65649128, g_loss: 0.89384246\n",
            "Epoch: [19/25] [   4/   8] time: 256.2006, d_loss: 1.46834064, g_loss: 0.66364634\n",
            "Epoch: [19/25] [   5/   8] time: 257.7863, d_loss: 1.80578542, g_loss: 0.64222634\n",
            "Epoch: [19/25] [   6/   8] time: 259.3639, d_loss: 1.65975726, g_loss: 0.87282634\n",
            "Epoch: [19/25] [   7/   8] time: 260.9423, d_loss: 2.04836512, g_loss: 0.40961444\n",
            "Epoch: [20/25] [   0/   8] time: 262.5088, d_loss: 1.44374108, g_loss: 1.27094293\n",
            "Epoch: [20/25] [   1/   8] time: 264.0800, d_loss: 1.43782651, g_loss: 0.77627158\n",
            "Epoch: [20/25] [   2/   8] time: 265.6652, d_loss: 1.48271823, g_loss: 0.85521281\n",
            "Epoch: [20/25] [   3/   8] time: 267.2473, d_loss: 1.20082855, g_loss: 0.95998847\n",
            "Epoch: [20/25] [   4/   8] time: 268.8417, d_loss: 1.39629042, g_loss: 0.69346499\n",
            "Epoch: [20/25] [   5/   8] time: 270.4214, d_loss: 1.43062377, g_loss: 0.80838543\n",
            "Epoch: [20/25] [   6/   8] time: 271.9923, d_loss: 1.32872534, g_loss: 0.75361097\n",
            "Epoch: [20/25] [   7/   8] time: 273.5594, d_loss: 1.16753590, g_loss: 0.95039147\n",
            "Epoch: [21/25] [   0/   8] time: 275.1256, d_loss: 1.57254553, g_loss: 0.63959205\n",
            "Epoch: [21/25] [   1/   8] time: 276.6988, d_loss: 1.67495966, g_loss: 0.97836012\n",
            "Epoch: [21/25] [   2/   8] time: 278.2772, d_loss: 1.85327709, g_loss: 0.59909856\n",
            "Epoch: [21/25] [   3/   8] time: 279.8646, d_loss: 1.62884235, g_loss: 1.05988741\n",
            "Epoch: [21/25] [   4/   8] time: 281.4326, d_loss: 1.50042772, g_loss: 0.44802201\n",
            "Epoch: [21/25] [   5/   8] time: 282.9976, d_loss: 1.52046359, g_loss: 1.51284790\n",
            "Epoch: [21/25] [   6/   8] time: 284.5682, d_loss: 1.46206367, g_loss: 0.54114825\n",
            "Epoch: [21/25] [   7/   8] time: 286.1519, d_loss: 1.35347128, g_loss: 0.98602915\n",
            "Epoch: [22/25] [   0/   8] time: 287.7358, d_loss: 1.30375886, g_loss: 0.66521502\n",
            "Epoch: [22/25] [   1/   8] time: 289.3218, d_loss: 1.10626698, g_loss: 1.27171874\n",
            "Epoch: [22/25] [   2/   8] time: 290.9152, d_loss: 1.62968707, g_loss: 0.40446299\n",
            "Epoch: [22/25] [   3/   8] time: 292.4809, d_loss: 1.83754730, g_loss: 1.60641527\n",
            "Epoch: [22/25] [   4/   8] time: 294.0577, d_loss: 1.67453218, g_loss: 0.49201635\n",
            "Epoch: [22/25] [   5/   8] time: 295.6240, d_loss: 1.17610598, g_loss: 1.19549704\n",
            "Epoch: [22/25] [   6/   8] time: 297.2068, d_loss: 1.27257776, g_loss: 0.70226526\n",
            "Epoch: [22/25] [   7/   8] time: 298.7961, d_loss: 1.70709372, g_loss: 0.56731135\n",
            "Epoch: [23/25] [   0/   8] time: 300.3673, d_loss: 1.20087504, g_loss: 1.34771132\n",
            "Epoch: [23/25] [   1/   8] time: 301.9370, d_loss: 1.61642420, g_loss: 0.35420132\n",
            "Epoch: [23/25] [   2/   8] time: 303.5108, d_loss: 1.18289065, g_loss: 1.79030871\n",
            "Epoch: [23/25] [   3/   8] time: 305.0822, d_loss: 1.53305638, g_loss: 0.48866045\n",
            "Epoch: [23/25] [   4/   8] time: 306.6886, d_loss: 1.52958000, g_loss: 0.88145912\n",
            "Epoch: [23/25] [   5/   8] time: 308.2774, d_loss: 1.45902729, g_loss: 0.81700468\n",
            "Epoch: [23/25] [   6/   8] time: 309.8594, d_loss: 1.26759601, g_loss: 0.72723746\n",
            "Epoch: [23/25] [   7/   8] time: 311.4378, d_loss: 0.96475387, g_loss: 1.44114447\n",
            "Epoch: [24/25] [   0/   8] time: 313.0048, d_loss: 1.68974888, g_loss: 0.38946378\n",
            "Epoch: [24/25] [   1/   8] time: 314.5855, d_loss: 1.69531155, g_loss: 1.36406600\n",
            "Epoch: [24/25] [   2/   8] time: 316.1785, d_loss: 2.07393098, g_loss: 0.24787727\n",
            "Epoch: [24/25] [   3/   8] time: 317.7656, d_loss: 1.53284848, g_loss: 1.24828494\n",
            "Epoch: [24/25] [   4/   8] time: 319.3399, d_loss: 1.36974907, g_loss: 0.81526649\n",
            "Epoch: [24/25] [   5/   8] time: 320.9242, d_loss: 1.26789641, g_loss: 0.77774143\n",
            "Epoch: [24/25] [   6/   8] time: 322.4930, d_loss: 1.46716225, g_loss: 0.68173254\n",
            "[Sample] d_loss: 1.40606582, g_loss: 0.95972133\n",
            "Epoch: [24/25] [   7/   8] time: 324.6304, d_loss: 1.39467525, g_loss: 0.87126315\n",
            " [*] 0\n",
            " [*] 1\n",
            " [*] 2\n",
            " [*] 3\n",
            " [*] 4\n",
            " [*] 5\n",
            " [*] 6\n",
            " [*] 7\n",
            " [*] 8\n",
            " [*] 9\n",
            " [*] 10\n",
            " [*] 11\n",
            " [*] 12\n",
            " [*] 13\n",
            " [*] 14\n",
            " [*] 15\n",
            " [*] 16\n",
            " [*] 17\n",
            " [*] 18\n",
            " [*] 19\n",
            " [*] 20\n",
            " [*] 21\n",
            " [*] 22\n",
            " [*] 23\n",
            " [*] 24\n",
            " [*] 25\n",
            " [*] 26\n",
            " [*] 27\n",
            " [*] 28\n",
            " [*] 29\n",
            " [*] 30\n",
            " [*] 31\n",
            " [*] 32\n",
            " [*] 33\n",
            " [*] 34\n",
            " [*] 35\n",
            " [*] 36\n",
            " [*] 37\n",
            " [*] 38\n",
            " [*] 39\n",
            " [*] 40\n",
            " [*] 41\n",
            " [*] 42\n",
            " [*] 43\n",
            " [*] 44\n",
            " [*] 45\n",
            " [*] 46\n",
            " [*] 47\n",
            " [*] 48\n",
            " [*] 49\n",
            " [*] 50\n",
            " [*] 51\n",
            " [*] 52\n",
            " [*] 53\n",
            " [*] 54\n",
            " [*] 55\n",
            " [*] 56\n",
            " [*] 57\n",
            " [*] 58\n",
            " [*] 59\n",
            " [*] 60\n",
            " [*] 61\n",
            " [*] 62\n",
            " [*] 63\n",
            " [*] 64\n",
            " [*] 65\n",
            " [*] 66\n",
            " [*] 67\n",
            " [*] 68\n",
            " [*] 69\n",
            " [*] 70\n",
            " [*] 71\n",
            " [*] 72\n",
            " [*] 73\n",
            " [*] 74\n",
            " [*] 75\n",
            " [*] 76\n",
            " [*] 77\n",
            " [*] 78\n",
            " [*] 79\n",
            " [*] 80\n",
            " [*] 81\n",
            " [*] 82\n",
            " [*] 83\n",
            " [*] 84\n",
            " [*] 85\n",
            " [*] 86\n",
            " [*] 87\n",
            " [*] 88\n",
            " [*] 89\n",
            " [*] 90\n",
            " [*] 91\n",
            " [*] 92\n",
            " [*] 93\n",
            " [*] 94\n",
            " [*] 95\n",
            " [*] 96\n",
            " [*] 97\n",
            " [*] 98\n",
            " [*] 99\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}